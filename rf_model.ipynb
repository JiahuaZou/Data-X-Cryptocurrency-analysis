{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avish\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import tweepy\n",
    "from tweepy import TweepError\n",
    "import json\n",
    "from datetime import timedelta, datetime, timezone, date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_file = 'keys.json'\n",
    "with open(key_file) as f:\n",
    "                keys = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(keys[\"consumer_key\"], keys[\"consumer_secret\"])\n",
    "auth.set_access_token(keys[\"access_token\"], keys[\"access_token_secret\"])\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's stick with tweets in the past day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "today = datetime(today.year, today.month, today.day)\n",
    "week_ago = today - timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = week_ago.strftime('%Y-%m-%d %H:%M:%S')[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A script to print every tweet with the hashtag \"bitcoin\" in the last week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change the value of i if you have trouble with tweepy.cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping tweeter data with hashtag bitcoin in the last day with tweepy\n"
     ]
    }
   ],
   "source": [
    "print(\"scraping tweeter data with hashtag bitcoin in the last day with tweepy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timestamp = []\n",
    "user = []\n",
    "text = []\n",
    "retweet_count = []\n",
    "i = 0\n",
    "for tweet in tweepy.Cursor(api.search, q = \"#bitcoin\", lang=\"en\", since = start).items():\n",
    "    #print(i)\n",
    "    i += 1\n",
    "    timestamp.append(tweet.created_at)\n",
    "    retweet_count.append(tweet.retweet_count)\n",
    "    text.append(tweet.text)\n",
    "    user.append(tweet.user.screen_name)\n",
    "    if i > 1500:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start2 = int(round(timestamp[-1].replace(tzinfo=timezone.utc).timestamp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawlink = \"http://api.bitcoincharts.com/v1/trades.csv?symbol=bitstampUSD\"\n",
    "link = rawlink + \"&start=\" + str(int(round(start2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download price data from Bitcoincharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading and cleaning price data\n"
     ]
    }
   ],
   "source": [
    "print(\"downloading and cleaning price data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 / unknown"
     ]
    }
   ],
   "source": [
    "filename = wget.download(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "btcprice = pd.read_csv(filename, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "btcprice.columns = ['unixtime', 'price', 'amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "converted_time = btcprice['unixtime'].apply(lambda x: datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'timestamp': timestamp, 'user': user, 'text' : text, 'retweet' : retweet_count}\n",
    "df = pd.DataFrame(data = d)\n",
    "df.to_csv(\"most_recent_tweet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "btcprice['timestamp'] = converted_time\n",
    "btcprice2 = btcprice.iloc[::50, :].reset_index()\n",
    "del btcprice2['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df.iloc[::-1].reset_index()\n",
    "del df2['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "btcprice2['timestamp'] = btcprice2['timestamp'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_direction(array):\n",
    "    direction = np.ones(len(array))\n",
    "    for i in range(len(array) - 1):\n",
    "        if array[i + 1] - array[i] < 0:\n",
    "            direction[i + 1] = 0\n",
    "    return(direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "btcprice2 = btcprice2.assign(direction = cal_direction(btcprice2['price'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging tweet data with price data by timestamp\n"
     ]
    }
   ],
   "source": [
    "print(\"merging tweet data with price data by timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "direction_tweet = np.zeros(len(df2))\n",
    "for x in range(len(df2)):\n",
    "    for y in range(len(btcprice2)):\n",
    "        if (btcprice2.loc[y, 'timestamp'] > df2.loc[x, 'timestamp']):\n",
    "            direction_tweet[x] = btcprice2.loc[y, 'direction']\n",
    "            break\n",
    "#direction_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### natural language processing, clean and stem the tweet text, and use tfidf vectorizer to vectorize the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean the tweet\n"
     ]
    }
   ],
   "source": [
    "print(\"clean the tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avish\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(analyzer=clean_text)\n",
    "x_tfidf = tfidf_vec.fit_transform(df2['text'])\n",
    "\n",
    "x_tfidf.columns = tfidf_vec.get_feature_names()\n",
    "x_counts_tfidf = pd.DataFrame(x_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_feature = pd.concat([df2[['retweet']], x_counts_tfidf], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_feature2 = x_feature.loc[:int(round(0.8*len(x_feature)))-1, :]\n",
    "direction_tweet2 = direction_tweet[:int(round(0.8*len(direction_tweet)))]\n",
    "x_est = x_feature.loc[int(round(0.8*len(x_feature))):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = int(round(0.8*len(x_feature2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_feature2.loc[:train_size-1, :]\n",
    "x_test = x_feature2.loc[train_size:, :]\n",
    "y_train = direction_tweet2[:train_size]\n",
    "y_test = direction_tweet2[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x_feature, direction_tweet, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training a random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model\n"
     ]
    }
   ],
   "source": [
    "print(\"training the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, max_depth=20, n_jobs=-1)\n",
    "rf_model = rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.383 / Recall: 0.872 / Accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_model.predict(x_test)\n",
    "if sum(y_pred == 0) >= sum(y_pred == 1):\n",
    "    label = 0\n",
    "else:\n",
    "    lebel = 1\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label= label, average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                        round(recall, 3),\n",
    "                                                        round((y_pred==y_test).sum() / len(y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the random forest model detects an downward trend based on conversations on tweet with a probability of 0.8433333333333334\n"
     ]
    }
   ],
   "source": [
    "y_est = rf_model.predict(x_est)\n",
    "p1 = sum(y_est == 1)\n",
    "p0 = sum(y_est == 0)\n",
    "if p1 > p0:\n",
    "    print(\"the random forest model detects an upward trend based on conversations on tweet with a probability of \" + str(p1/len(y_est)))\n",
    "else:\n",
    "    print(\"the random forest model detects an downward trend based on conversations on tweet with a probability of \" + str(p0/len(y_est)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
